# üìå OneDrive ‚Üí Vector Database (RAG Pipeline)

## **Overview**
This pipeline is designed to **ingest PowerPoint files from OneDrive**, generate **summarized embeddings**, and store them in a **vector database (Pinecone)** for efficient retrieval.  

Instead of embedding entire documents, we use a **hybrid approach** that generates:  
- **A summary** of each PowerPoint file.  
- **Key insights from tables and charts** on slides.  
- **Metadata** to improve searchability.

---

## **üöÄ Pipeline Steps**
### **1Ô∏è‚É£ Ensure OneDrive Files Sync Locally**
- Ensure OneDrive is **fully synced** on the local machine or GPU instance.
- **All PowerPoint files should be accessible locally** for processing.
- Make sure the OneDrive folder is **set to always keep files available offline** (avoid "Files on Demand" mode).

---

### **2Ô∏è‚É£ Define the Root Folder for Ingestion**
- The script/API takes a **root folder path** that contains all synced **OneDrive PowerPoint files**.
- **For V1:** Focus only on **a single folder** (e.g., `/OneDrive/Documents/AI_PPTs/`).
- Future versions can support **recursive folder scanning** or **additional file types**.

---

### **3Ô∏è‚É£ Implement a Sync Mechanism (Modified-Date Based)**
- The pipeline **only processes files that have changed** to minimize redundancy.
- Steps:
  1. Maintain a **log or database** (`processed_files.json`) that tracks each file‚Äôs **last modified date**.
  2. If a file‚Äôs modified date **has not changed**, **skip processing**.
  3. If a file **has changed**, reprocess and update the log.
  4. If a file **was deleted**, remove its embeddings from the vector database.

---

### **4Ô∏è‚É£ Traverse OneDrive Folder & Extract PowerPoint Content**
- The script **scans all `.pptx` files** in the target folder.
- **For V1:** Ignore all other file types.
- Extract **text, tables, and charts** from each slide using `python-pptx`:
  - **Text:** Slide titles & bullet points.
  - **Tables:** Extracted & summarized by an LLM.
  - **Charts/Graphs:** Converted to images, analyzed via OCR/LLM for insights.

---

### **5Ô∏è‚É£ Summarization & Embedding**
- Each slide is **processed by an LLM** to generate:
  - **A structured summary of the PowerPoint file.**
  - **Key insights from tables (if present).**
  - **Key takeaways from charts/graphs (if present).**
- The LLM **does not store raw table/chart data**‚Äîonly summarized insights.
- Convert:
  - **Summary ‚Üí 1 embedding**
  - **Key insights ‚Üí Separate embeddings**
- Metadata stored includes:
  - **File Name**
  - **Slide Number**
  - **OneDrive Link**
  - **Last Modified Date**
  - **Embedding Type (summary/key passage)**

---

### **6Ô∏è‚É£ Store Embeddings in Vector Database (Pinecone)**
- Insert embeddings **in batches** to improve performance.
- Attach **metadata** to embeddings to support advanced filtering.
- If a file is **deleted from OneDrive**, remove its corresponding vectors.

---

### **7Ô∏è‚É£ Query Processing & AI Retrieval**
- When a user queries the system:
  1. Convert the **query into an embedding**.
  2. Search Pinecone for **matching summaries & key insights**.
  3. Return:
     - **Relevant file names**
     - **Slide numbers**
     - **OneDrive links**
     - **A confidence score**
  4. If the AI **is not confident**, suggest refining the query or show related results.

---

## **üéØ Goals for V1**
‚úÖ **Minimize redundant processing** ‚Üí Only update embeddings when a file changes.  
‚úÖ **Prioritize useful retrieval** ‚Üí Use **summary + key insights** instead of storing full documents.  
‚úÖ **Ensure metadata-driven searchability** ‚Üí Improve retrieval with **file names, slide numbers, and links**.  
‚úÖ **Deploy a scalable approach** ‚Üí Start simple with **PowerPoint-only ingestion**, then expand to other file types.  

---

## **üîÆ Future Enhancements**
- **Multi-folder support**: Allow scanning multiple OneDrive directories.
- **Additional file types**: Expand to PDFs, Word docs, and Excel sheets.
- **Hybrid search**: Combine vector search with **keyword-based retrieval**.
- **Automated reprocessing**: Implement a scheduled job to **run daily** and update embeddings.

---

## **üí° Why This Approach?**
This pipeline **balances retrieval accuracy, performance, and cost** by:
- **Avoiding full-document chunking** (which would be expensive to store and retrieve).  
- **Prioritizing AI-generated summaries** to capture key insights.  
- **Keeping metadata intact** for easy navigation and reference.  

This ensures an **efficient and practical RAG implementation** that provides **high-quality search results** without unnecessary storage overhead.

---

## **üìå Next Steps**
Would you like to implement this pipeline as a **Python script**, or do you prefer an **API-based solution** for greater flexibility? üöÄ
√ü