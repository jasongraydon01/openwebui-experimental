# OpenWebUI-Setup: Local AI & RAG System

## Overview
This repository contains the implementation of a **local AI-powered system** using **Open WebUI** as the interface. The system is designed to be fully modular and containerized, allowing for deployment on both a local machine and a **GPU cloud instance** for up to **100 consultants**. 

## Project Goals
- **Build a Retrieval-Augmented Generation (RAG) system** that integrates with OneDrive for enterprise knowledge retrieval.
- **Develop AI agent workflows** to handle multi-step queries beyond basic RAG.
- **Customize Open WebUI** for structured AI interactions, folder organization, and metadata displays.
- **Ensure portability** by packaging everything into a Docker container that can run on both local and cloud GPU instances.

---

## Roadmap & Execution Plan

### **Phase 1: Core RAG Pipeline**
#### **1. OneDrive Data Ingestion**
- Authenticate and connect to **Microsoft OneDrive**.
- Extract and preprocess files (**PowerPoint, PDFs, Word, Excel**).
- Define metadata structures (file names, slide numbers, etc.).

#### **2. Embedding & Vector Storage**
- Convert text into embeddings using **nomic-embed-text**.
- Store embeddings in **Pinecone** for efficient retrieval.
- Define retrieval strategies (**chunking, metadata filtering**).

#### **3. Query Processing & Retrieval**
- Implement **search logic** for retrieving relevant documents.
- Return references (slide numbers, file links) **inside Open WebUI**.

---

### **Phase 2: AI Agent Workflows**
#### **1. Request Classification System**
- Build a lightweight backend service to:
  - Determine if a request requires **RAG retrieval or general AI processing**.
  - Route the request accordingly.
- Store logic in **Python or TypeScript** (without external frameworks initially).

#### **2. Agent Execution**
- Implement AI workflows beyond simple retrieval:
  - **Multi-step queries**
  - **Summarization & key insight extraction**

---

### **Phase 3: Open WebUI Enhancements**
#### **1. UI & Structural Improvements**
- Modify **Open WebUI** to:
  - Support **folder organization** for structured data access.
  - Display metadata (file names, sources, etc.).
  - Improve prompt handling for different workflows.

#### **2. Backend Integration**
- Modify Open WebUI to **send queries to the request classification system**.
- Ensure proper routing between Open WebUI and the backend AI pipeline.

---

### **Phase 4: Deployment & Containerization**
#### **1. Containerize the System**
- Build a **Docker image** that includes:
  - Open WebUI
  - Backend for workflow routing
  - Vector DB connection (**Pinecone**)
- Ensure **persistent storage** (e.g., mounted volumes for state retention).

#### **2. Test Portability**
- Deploy the container on a **cloud GPU instance (RunPod)** with minimal configuration changes.
- Validate **model performance and system behavior** in a near-production environment.

---

## Final Repository Structure
```plaintext
openwebui-setup/
â”‚â”€â”€ backend/                     # Backend logic (request classification, AI workflows)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # Main API entry point
â”‚   â”œâ”€â”€ routes.py                  # API routes (handles RAG vs. general AI processing)
â”‚   â”œâ”€â”€ agent_workflows.py         # AI agent execution logic
â”‚   â”œâ”€â”€ rag_pipeline.py            # RAG retrieval functions
â”‚   â”œâ”€â”€ vector_db.py               # Pinecone vector database interactions
â”‚   â”œâ”€â”€ onedrive_ingestion.py      # OneDrive data extraction & processing
â”‚
â”‚â”€â”€ openwebui/                     # Open WebUI customizations
â”‚   â”œâ”€â”€ docker-compose.yml         # Docker Compose for WebUI + backend
â”‚   â”œâ”€â”€ webui-mods/                # UI modifications
â”‚   â”‚   â”œâ”€â”€ components/            # UI components (e.g., folder structure UI)
â”‚   â”‚   â”œâ”€â”€ config/                # WebUI-specific settings
â”‚   â”‚   â”œâ”€â”€ api.js                 # Modify how WebUI sends requests to backend
â”‚   â”‚   â”œâ”€â”€ routes.js              # Custom UI routing
â”‚
â”‚â”€â”€ models/                        # Model-related setup
â”‚   â”œâ”€â”€ model_config.yaml          # Defines which models are used
â”‚   â”œâ”€â”€ download_models.sh         # Script to pull models locally
â”‚
â”‚â”€â”€ scripts/                       # Utility scripts for setup and maintenance
â”‚   â”œâ”€â”€ init_env.sh                # Environment setup script
â”‚   â”œâ”€â”€ deploy_container.sh        # Automates deployment to GPU instance
â”‚
â”‚â”€â”€ config/                        # Configuration files
â”‚   â”œâ”€â”€ .env                       # API keys, secrets, etc.
â”‚   â”œâ”€â”€ settings.yaml               # System-wide configurations
â”‚
â”‚â”€â”€ Dockerfile                     # Main Dockerfile for full system containerization
â”‚â”€â”€ docker-compose.yml              # Docker Compose for local & cloud deployment
â”‚â”€â”€ requirements.txt                # Python dependencies
â”‚â”€â”€ README.md                       # Documentation
â”‚â”€â”€ .gitignore                      # Ignore logs, credentials, etc.
```

---

## Current Implementation
Currently, this repository only contains a **basic Open WebUI setup** with the following `docker-compose.yml`:
```yaml
version: '3'
services:
  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "3000:8080"
    volumes:
      - open-webui:/app/backend/data
volumes:
  open-webui:
```

---

## Next Steps
- Implement **OneDrive ingestion & file processing**.
- Build the **embedding pipeline & integrate with Pinecone**.
- Implement **retrieval & test querying** inside Open WebUI.
- Develop the **request classification system** for routing RAG vs. general AI processing.
- Modify **Open WebUI UI** for better **folder structure + metadata display**.
- **Containerize the entire system** and validate portability on a **RunPod GPU instance**.

This document will be updated as the project progresses. ðŸš€
